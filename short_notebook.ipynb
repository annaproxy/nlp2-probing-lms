{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from conllu import parse_incr, TokenList\n",
    "from torch import Tensor\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "CUTOFF = None\n",
    "from lstm.model import RNNModel\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready\n",
      "Tokenizer ready\n"
     ]
    }
   ],
   "source": [
    "transformer = GPT2Model.from_pretrained('distilgpt2', output_hidden_states=True)\n",
    "print(\"Model ready\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "print(\"Tokenizer ready\")\n",
    "# Note that some models don't return the hidden states by default.\n",
    "# This can be configured by passing `output_hidden_states=True` to the `from_pretrained` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gulordava LSTM model can be found here: \n",
    "# https://drive.google.com/open?id=1w47WsZcZzPyBKDn83cMNd0Hb336e-_Sy\n",
    "#\n",
    "# N.B: I have altered the RNNModel code to only output the hidden states that you are interested in.\n",
    "# If you want to do more experiments with this model you could have a look at the original code here:\n",
    "# https://github.com/facebookresearch/colorlessgreenRNNs/blob/master/src/language_models/model.py\n",
    "#\n",
    "model_location = 'lstm/gulordava.pt'\n",
    "lstm = RNNModel('LSTM', 50001, 650, 650, 2)\n",
    "lstm.load_state_dict(torch.load(model_location))\n",
    "\n",
    "\n",
    "# This LSTM does not use a Tokenizer like the Transformers, but a Vocab dictionary that maps a token to an id.\n",
    "with open('lstm/vocab.txt') as f:\n",
    "    w2i = {w.strip(): i for i, w in enumerate(f)}\n",
    "\n",
    "vocabLSTM = defaultdict(lambda: w2i[\"<unk>\"])\n",
    "vocabLSTM.update(w2i)\n",
    "i2w = { w2i[k]:k for k in w2i}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import create_or_load_pos_data\n",
    "from controltasks import save_or_load_pos_controls \n",
    "from datasets import find_distribution, POSDataset\n",
    "import torch.utils.data as data \n",
    "import time\n",
    "\n",
    "train_x, train_y, vocab, words_train = create_or_load_pos_data(\"train\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "dev_x, dev_y, vocab, words_dev = create_or_load_pos_data(\"dev\", transformer, tokenizer, vocab, cutoff=CUTOFF)\n",
    "test_x, test_y, vocab, words_test = create_or_load_pos_data(\"test\", transformer, tokenizer, vocab, cutoff=CUTOFF)\n",
    "\n",
    "flatten_train = [word for sublist in words_train for word in sublist]\n",
    "flatten_dev   = [word for sublist in words_dev for word in sublist]\n",
    "flatten_test  = [word for sublist in words_test for word in sublist]\n",
    "dist = find_distribution(data.DataLoader(POSDataset(train_x, train_y), batch_size=1))\n",
    "ypos_train_control, ypos_dev_control, ypos_test_control = save_or_load_pos_controls(\n",
    "    train_x, train_y, [flatten_train, flatten_dev, flatten_test], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xL, train_yL, vocab, _ = create_or_load_pos_data(\"train\", lstm, vocabLSTM, cutoff=CUTOFF)\n",
    "dev_xL, dev_yL, vocab, _ = create_or_load_pos_data(\"dev\", lstm, vocabLSTM, vocab, cutoff=CUTOFF)\n",
    "test_xL, test_yL, vocab, _ = create_or_load_pos_data(\"test\", lstm, vocabLSTM, vocab, cutoff=CUTOFF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_utils import create_or_load_structural_data\n",
    "from controltasks import save_or_load_struct_controls\n",
    "\n",
    "train_xy = create_or_load_structural_data(\"train\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "dev_xy = create_or_load_structural_data(\"dev\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "test_xy = create_or_load_structural_data(\"test\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "print(len(train_xy))\n",
    "struct_train_control, struct_dev_control, struct_test_control = save_or_load_struct_controls(cutoff=CUTOFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC CLASSIFIER\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "class POSProbe(nn.Module):\n",
    "    def __init__(self, repr_size, pos_size, hidden_size = 0, dropout=0):\n",
    "        super().__init__()\n",
    "        if hidden_size == 0:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(repr_size, pos_size))\n",
    "        else:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(repr_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(hidden_size, pos_size)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "def eval_given_dataloader(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for x,y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs,dim=1)\n",
    "        c = torch.sum(torch.eq(preds, y))\n",
    "        correct += c.item()\n",
    "        total += y.shape[0]\n",
    "    return correct/total\n",
    "    \n",
    "def train(my_model, train_loader, dev_loader, epoch_amount = 10, warmup_steps = 5, p=False):\n",
    "    \"\"\"\n",
    "    Given a model, train_loader and dev_loader\n",
    "    \n",
    "    Returns state_dict for the best epoch\n",
    "    \"\"\"\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(my_model.parameters())\n",
    "    patience = 3\n",
    "    best_model = None\n",
    "    prev_dev_acc = 0.0\n",
    "    best_dev_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    for i in range(epoch_amount):\n",
    "        my_model.train()\n",
    "        epoch_correct = 0.0\n",
    "        epoch_total = 0.0\n",
    "        for x,y in train_loader:\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = my_model(x)\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            correct = torch.sum(torch.eq(preds, y))\n",
    "            accuracy = correct.item()/y.shape[0]\n",
    "            loss = ce(outputs, y)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            epoch_correct += correct.item()\n",
    "            epoch_total += y.shape[0]\n",
    "            \n",
    "        dev_acc = eval_given_dataloader(dev_loader, my_model)\n",
    "        \n",
    "        if p:\n",
    "            print(\"Epoch\",i,\"accuracy\", epoch_correct/epoch_total, dev_acc)        \n",
    "        if dev_acc < prev_dev_acc and i > warmup_steps:\n",
    "            patience -= 1\n",
    "        else:\n",
    "            patience = 2\n",
    "        if dev_acc > best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            best_model = copy.deepcopy(my_model.state_dict())\n",
    "            best_epoch = i\n",
    "        prev_dev_acc = dev_acc\n",
    "        if patience == 0:\n",
    "            #print(\"Early stopping\")\n",
    "            break\n",
    "    return best_model, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Starting lstm\n",
      "controlpos lstm 256 0 10 4 0.6767213898629264\n",
      "controlpos lstm 256 0 20 5 0.6752868983104877\n",
      "controlpos lstm 256 0 30 4 0.6733742429072362\n",
      "controlpos lstm 256 0.2 10 16 0.687041759642971\n",
      "controlpos lstm 256 0.2 20 19 0.6845712464137711\n",
      "controlpos lstm 256 0.2 30 6 0.6713021995537137\n",
      "controlpos lstm 256 0.4 10 19 0.6465572202741473\n",
      "controlpos lstm 256 0.4 20 19 0.645680586547657\n",
      "controlpos lstm 256 0.4 30 18 0.6455610455849538\n",
      "controlpos lstm 256 0.6 10 13 0.5783391775581767\n",
      "controlpos lstm 256 0.6 20 14 0.58057060886197\n",
      "controlpos lstm 256 0.6 30 18 0.582403570290086\n",
      "controlpos lstm 256 0.8 10 18 0.46545266177876954\n",
      "controlpos lstm 256 0.8 20 9 0.46449633407714375\n",
      "controlpos lstm 256 0.8 30 19 0.4686404207841887\n",
      "Starting transformer\n",
      "controlpos transformer 256 0 10 14 0.6807857825948358\n",
      "controlpos transformer 256 0 20 8 0.674489958559133\n",
      "controlpos transformer 256 0 30 14 0.6805467006694293\n",
      "controlpos transformer 256 0.2 10 19 0.6605036659228563\n",
      "controlpos transformer 256 0.2 20 15 0.6605833598979917\n",
      "controlpos transformer 256 0.2 30 8 0.6559611093401339\n",
      "controlpos transformer 256 0.4 10 18 0.6108144724258846\n",
      "controlpos transformer 256 0.4 20 19 0.6116911061523749\n",
      "controlpos transformer 256 0.4 30 8 0.6024067580490915\n",
      "controlpos transformer 256 0.6 10 12 0.5370975454255659\n",
      "controlpos transformer 256 0.6 20 15 0.538452343002869\n",
      "controlpos transformer 256 0.6 30 15 0.5368983104877272\n",
      "controlpos transformer 256 0.8 10 9 0.36766815428753585\n",
      "controlpos transformer 256 0.8 20 18 0.38018010838380617\n",
      "controlpos transformer 256 0.8 30 14 0.37966209754542557\n",
      "All results are safe. You can sleep peacefully. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/.local/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# MLP vs LINEAR\n",
    "# Dropout 0.0 0.2 0.4 0.6 0.8 \n",
    "# POS CONTROLPOS\n",
    "# RNN vs Transformer\n",
    "# result_dict[task][model][mlp][dropout][seed] -> bestmodel: statedict, val_acc: float, test_acc:float\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "if os.path.exists('results_mlp.pickle'):\n",
    "    raise ValueError(\"Do not run this ... \")\n",
    "\n",
    "def eval_model(task, model_type, hidden_size, dropout, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        x_train = train_xL\n",
    "        x_dev = dev_xL \n",
    "        x_test = test_xL\n",
    "    else:\n",
    "        x_train = train_x\n",
    "        x_dev = dev_x\n",
    "        x_test = test_x\n",
    "    \n",
    "    if task == 'pos':\n",
    "        y_train = train_y\n",
    "        y_dev = dev_y\n",
    "        y_test = test_y\n",
    "    else:\n",
    "        y_train = ypos_train_control\n",
    "        y_dev = ypos_dev_control\n",
    "        y_test = ypos_test_control\n",
    "        \n",
    "    train_loader = data.DataLoader(POSDataset(x_train, y_train), batch_size=16, shuffle=True)\n",
    "    dev_loader = data.DataLoader(POSDataset(x_dev, y_dev), batch_size=16)\n",
    "    test_loader = data.DataLoader(POSDataset(x_test, y_test), batch_size=16)\n",
    "\n",
    "    model = POSProbe(768 if model_type == 'transformer' else 650, len(dist), hidden_size, dropout).to(device)\n",
    "    best_state_dict, epochs = train(model, train_loader, dev_loader, 20, 4)\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    dev_acc =  eval_given_dataloader(dev_loader, model)\n",
    "    test_acc = eval_given_dataloader(test_loader, model)\n",
    "    return model, dev_acc, test_acc, epochs\n",
    "print(device)\n",
    "result_dict_mlp = {}   \n",
    "for task in [ 'controlpos']:\n",
    "    result_dict_mlp[task] = {}\n",
    "    for model_type in ['lstm', 'transformer']:\n",
    "        print(\"Starting\", model_type)\n",
    "        result_dict_mlp[task][model_type]= {}\n",
    "        for hidden_size in [256]:\n",
    "            result_dict_mlp[task][model_type][hidden_size] = {}\n",
    "            for dropout in [0,0.2,0.4,0.6,0.8]:\n",
    "                result_dict_mlp[task][model_type][hidden_size][dropout] = {}\n",
    "                for seed in [10,20,30]:\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed] = {}\n",
    "                    state_dict, dev_acc, test_acc, epochs = eval_model(task, model_type, hidden_size, dropout, seed)\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['state_dict'] = state_dict\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['dev_acc'] = dev_acc\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['test_acc'] = test_acc\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['epochs'] = epochs\n",
    "                    print(task,model_type,hidden_size,dropout,seed, epochs, test_acc)\n",
    "                #print(result_dict)       \n",
    "with open(\"results_mlpcontrolpos.pickle\", \"wb\") as f:\n",
    "    pickle.dump(result_dict_mlp, f)\n",
    "print(\"All results are safe. You can sleep peacefully. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_pos.pickle\", \"rb\") as f:\n",
    "    mlp_results = pickle.load(f)\n",
    "    \n",
    "with open(\"results_mlpcontrolpos.pickle\", \"rb\") as f:\n",
    "    mlp_results2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "with open('Justnumbers.txt', 'rb') as f:\n",
    "    result_dict = pickle.load(f)\n",
    "    \n",
    "def mean_test_acc(the_dict):\n",
    "    three_accs = [the_dict[z]['test_acc'] for z in the_dict]\n",
    "    return np.mean(three_accs), np.std(three_accs)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "\n",
    "for model in ['lstm', 'transformer']:\n",
    "    for hidden_size in [0, 256]:\n",
    "        x_axis = [0,0.2,0.4,0.6,0.8]\n",
    "        y_axis = []\n",
    "        y_axis_control = []\n",
    "        y_axis_select = []\n",
    "        for d in x_axis :\n",
    "            # Mean for POS task\n",
    "            mean = mean_test_acc(result_dict['pos'][model][hidden_size][d])\n",
    "            if hidden_size > 0: mean = mean_test_acc(mlp_results['pos'][model][hidden_size][d])\n",
    "            \n",
    "            # Mean for Control task\n",
    "            mean_control = mean_test_acc(result_dict['controlpos'][model][hidden_size][d])\n",
    "            if hidden_size > 0: mean_control = mean_test_acc(mlp_results2['controlpos'][model][hidden_size][d])\n",
    "            \n",
    "            # Append\n",
    "            y_axis.append(mean[0])\n",
    "            y_axis_select.append(mean[0] - mean_control[0])\n",
    "\n",
    "        ax1.plot(x_axis, y_axis, '--o', label=model+str(hidden_size), )\n",
    "        ax2.plot(x_axis, y_axis_select, '--o')\n",
    "        ax1.legend()\n",
    "    \n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax2.set_title(\"Selectivity\")\n",
    "ax1.set_xlabel(\"Dropout\")\n",
    "ax2.set_xlabel(\"Dropout\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This was a temporary fix. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-35e50fb8a69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This was a temporary fix. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult_dict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'controlpos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult_dict1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transformer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This was a temporary fix. "
     ]
    }
   ],
   "source": [
    "\n",
    "raise ValueError(\"This was a temporary fix. \")\n",
    "result_dict1 = {}\n",
    "for task in ['pos', 'controlpos']:\n",
    "    result_dict1[task] = {}\n",
    "    for model_type in ['lstm', 'transformer']:\n",
    "        result_dict1[task][model_type]= {}\n",
    "        for hidden_size in [0, 256]:\n",
    "            result_dict1[task][model_type][hidden_size] = {}\n",
    "            for dropout in [0,0.2,0.4,0.6,0.8]:\n",
    "                result_dict1[task][model_type][hidden_size][dropout] = {}\n",
    "                for seed in [10,20,30]:\n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed] = {}\n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed]['dev_acc'] =result_dict[task][model_type][hidden_size][dropout][seed]['dev_acc']\n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed]['test_acc'] =result_dict[task][model_type][hidden_size][dropout][seed]['test_acc']                    \n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed]['epochs'] =result_dict[task][model_type][hidden_size][dropout][seed]['epochs']                    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy 0.9034191167485397 0.9160171783044377\n",
      "Epoch 1 accuracy 0.9309333528851089 0.9188006998568474\n",
      "Epoch 2 accuracy 0.9378204658210524 0.9171305869254016\n",
      "Epoch 3 accuracy 0.9428745997995943 0.9214251630348338\n",
      "Epoch 4 accuracy 0.9461446342595987 0.9270319707332592\n",
      "Epoch 5 accuracy 0.9484810714372999 0.9250039764593606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-96c5ef27792c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOSProbe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dev accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_given_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_given_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-6a16d8db986a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(my_model, train_loader, dev_loader, epoch_amount, warmup_steps, p)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Normal task\n",
    "ntrain_loader = data.DataLoader(POSDataset(train_x, train_y), batch_size=16, shuffle=True)\n",
    "ndev_loader = data.DataLoader(POSDataset(dev_x, dev_y), batch_size=16)\n",
    "ntest_loader = data.DataLoader(POSDataset(test_x, test_y), batch_size=16)\n",
    "\n",
    "model = POSProbe(768, len(dist), hidden_size=256).to(device)\n",
    "model.load_state_dict(train(model, ntrain_loader, ndev_loader, 20, 6, p=True))\n",
    "print(\"Dev accuracy\", eval_given_dataloader(ndev_loader, model))\n",
    "print(\"Test accuracy\", eval_given_dataloader(ntest_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmtrain_loader = data.DataLoader(POSDataset(train_xL, train_yL), batch_size=16, shuffle=True)\n",
    "lstmdev_loader = data.DataLoader(POSDataset(dev_xL, dev_yL), batch_size=16)\n",
    "lstmtest_loader = data.DataLoader(POSDataset(test_xL, test_yL), batch_size=16)\n",
    "print(train_xL.shape, train_yL.shape)\n",
    "model = POSProbe(650, len(dist)).to(device)\n",
    "model.load_state_dict(train(model, lstmtrain_loader, lstmdev_loader, 20,6))\n",
    "print(\"Dev accuracy\", eval_given_dataloader(lstmdev_loader, model))\n",
    "print(\"Test accuracy\", eval_given_dataloader(lstmtest_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([204585, 768]) (204585,)\n",
      "Epoch 0 accuracy 0.5665322482097905 0.5875218705264832\n",
      "Epoch 1 accuracy 0.6460297675782682 0.6224351837124225\n",
      "Epoch 2 accuracy 0.6769215729403426 0.628240814378877\n",
      "Epoch 3 accuracy 0.6952904660654495 0.6398123111181804\n",
      "Epoch 4 accuracy 0.7086247769875602 0.6393351359949101\n",
      "Epoch 5 accuracy 0.7182638023315492 0.6470097025608398\n",
      "Epoch 6 accuracy 0.7262164870347289 0.6505487513917608\n",
      "Epoch 7 accuracy 0.7332746780066964 0.6466518212183872\n",
      "Epoch 8 accuracy 0.7395019185179754 0.6517416891999364\n",
      "Epoch 9 accuracy 0.7446342595986998 0.6437490058851598\n",
      "Epoch 10 accuracy 0.7490334090964635 0.6550421504692222\n",
      "Epoch 11 accuracy 0.7530268592516558 0.6587800222681724\n",
      "Epoch 12 accuracy 0.7560818241806584 0.6526165102592651\n",
      "Epoch 13 accuracy 0.7603147835862845 0.6552409734372515\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-122609df70b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypos_train_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOSProbe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_given_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-6a16d8db986a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(my_model, train_loader, dev_loader, epoch_amount, warmup_steps, p)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mepoch_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normal task\n",
    "ctrain_loader = data.DataLoader(POSDataset(train_x, ypos_train_control), batch_size=16)\n",
    "cdev_loader = data.DataLoader(POSDataset(dev_x, ypos_dev_control), batch_size=16)\n",
    "ctest_loader = data.DataLoader(POSDataset(test_x, ypos_test_control), batch_size=16)\n",
    "print(train_x.shape, ypos_train_control.shape)\n",
    "model = POSProbe(768, len(dist), hidden_size=256).to(device)\n",
    "model.load_state_dict(train(model, ctrain_loader, cdev_loader, 20, p=True))\n",
    "print(\"Test accuracy\", eval_given_dataloader(ctest_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal task\n",
    "ctrain_loader = data.DataLoader(POSDataset(train_xL, ypos_train_control), batch_size=16)\n",
    "cdev_loader = data.DataLoader(POSDataset(dev_xL, ypos_dev_control), batch_size=16)\n",
    "ctest_loader = data.DataLoader(POSDataset(test_xL, ypos_test_control), batch_size=16)\n",
    "print(train_x.shape, ypos_train_control.shape)\n",
    "model = POSProbe(650, len(dist)).to(device)\n",
    "model.load_state_dict(train(model, ctrain_loader, cdev_loader, 20))\n",
    "print(\"Test accuracy\", eval_given_dataloader(ctest_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 10\n",
      "2 This 3\n",
      "3 killing 10\n",
      "4 of 7\n",
      "5 a 7\n",
      "6 respected 7\n",
      "7 cleric 3\n",
      "8 will 10\n",
      "9 be 10\n",
      "10 causing 0\n",
      "11 us 10\n",
      "12 trouble 10\n",
      "13 for 14\n",
      "14 years 10\n",
      "15 to 16\n",
      "16 come 14\n",
      "17 . 10\n",
      "18 ] 10\n",
      "===========================TRUE\n",
      "['10', '1', '3', '8', '9', '11', '12', '14', '17', '18', '2', '7', '13', '16', '4', '5', '6', '15']\n",
      "tensor([[0., 3., 2., 4., 4., 4., 3., 2., 2., 1., 2., 2., 3., 2., 4., 3., 2., 2.],\n",
      "        [3., 0., 1., 3., 3., 3., 2., 3., 3., 2., 3., 3., 4., 3., 5., 4., 3., 3.],\n",
      "        [2., 1., 0., 2., 2., 2., 1., 2., 2., 1., 2., 2., 3., 2., 4., 3., 2., 2.],\n",
      "        [4., 3., 2., 0., 2., 2., 1., 4., 4., 3., 4., 4., 5., 4., 6., 5., 4., 4.],\n",
      "        [4., 3., 2., 2., 0., 2., 1., 4., 4., 3., 4., 4., 5., 4., 6., 5., 4., 4.],\n",
      "        [4., 3., 2., 2., 2., 0., 1., 4., 4., 3., 4., 4., 5., 4., 6., 5., 4., 4.],\n",
      "        [3., 2., 1., 1., 1., 1., 0., 3., 3., 2., 3., 3., 4., 3., 5., 4., 3., 3.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 0., 2., 1., 2., 2., 3., 2., 4., 3., 2., 2.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 2., 0., 1., 2., 2., 3., 2., 4., 3., 2., 2.],\n",
      "        [1., 2., 1., 3., 3., 3., 2., 1., 1., 0., 1., 1., 2., 1., 3., 2., 1., 1.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 2., 2., 1., 0., 2., 3., 2., 4., 3., 2., 2.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 2., 2., 1., 2., 0., 3., 2., 4., 3., 2., 2.],\n",
      "        [3., 4., 3., 5., 5., 5., 4., 3., 3., 2., 3., 3., 0., 1., 3., 2., 3., 3.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 2., 2., 1., 2., 2., 1., 0., 2., 1., 2., 2.],\n",
      "        [4., 5., 4., 6., 6., 6., 5., 4., 4., 3., 4., 4., 3., 2., 0., 1., 4., 4.],\n",
      "        [3., 4., 3., 5., 5., 5., 4., 3., 3., 2., 3., 3., 2., 1., 1., 0., 3., 3.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 2., 2., 1., 2., 2., 3., 2., 4., 3., 0., 2.],\n",
      "        [2., 3., 2., 4., 4., 4., 3., 2., 2., 1., 2., 2., 3., 2., 4., 3., 2., 0.]])\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{(9, 10), (9, 16), (1, 2), (9, 13), (4, 6), (0, 9), (12, 13), (7, 9), (2, 9), (13, 15), (8, 9), (2, 6), (5, 6), (3, 6), (9, 11), (9, 17), (14, 15)}\n",
      "1 [ 18\n",
      "2 This 1\n",
      "3 killing 18\n",
      "4 of 1\n",
      "5 a 18\n",
      "6 respected 18\n",
      "7 cleric 18\n",
      "8 will 1\n",
      "9 be 1\n",
      "10 causing 18\n",
      "11 us 1\n",
      "12 trouble 18\n",
      "13 for 18\n",
      "14 years 18\n",
      "15 to 18\n",
      "16 come 18\n",
      "17 . 18\n",
      "18 ] 18\n",
      "===========================FAKE\n",
      "tensor([[0., 1., 2., 1., 2., 2., 2., 1., 1., 2., 1., 2., 2., 2., 2., 2., 2., 1.],\n",
      "        [1., 0., 3., 2., 3., 3., 3., 2., 2., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
      "        [2., 3., 0., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
      "        [1., 2., 3., 0., 3., 3., 3., 2., 2., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
      "        [2., 3., 2., 3., 0., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 0., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 2., 0., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
      "        [1., 2., 3., 2., 3., 3., 3., 0., 2., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
      "        [1., 2., 3., 2., 3., 3., 3., 2., 0., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 0., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
      "        [1., 2., 3., 2., 3., 3., 3., 2., 2., 3., 0., 3., 3., 3., 3., 3., 3., 2.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 0., 2., 2., 2., 2., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 0., 2., 2., 2., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 0., 2., 2., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 0., 2., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 0., 2., 1.],\n",
      "        [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 0., 1.],\n",
      "        [1., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "[[0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{(0, 1), (0, 7), (12, 17), (2, 17), (0, 10), (13, 17), (14, 17), (15, 17), (0, 3), (5, 17), (6, 17), (9, 17), (11, 17), (0, 8), (4, 17), (16, 17), (0, 17)}\n",
      "1 DPA 0\n",
      "2 : 1\n",
      "3 Iraqi 4\n",
      "4 authorities 5\n",
      "5 announced 1\n",
      "6 that 9\n",
      "7 they 9\n",
      "8 had 9\n",
      "9 busted 5\n",
      "10 up 9\n",
      "11 3 13\n",
      "12 terrorist 13\n",
      "13 cells 9\n",
      "14 operating 13\n",
      "15 in 16\n",
      "16 Baghdad 14\n",
      "17 . 1\n",
      "===========================TRUE\n",
      "['1', '2', '5', '17', '4', '9', '3', '6', '7', '8', '10', '13', '11', '12', '14', '16', '15']\n",
      "tensor([[0., 1., 3., 2., 1., 3., 3., 3., 2., 3., 4., 4., 3., 4., 6., 5., 1.],\n",
      "        [1., 0., 4., 3., 2., 4., 4., 4., 3., 4., 5., 5., 4., 5., 7., 6., 2.],\n",
      "        [3., 4., 0., 1., 2., 4., 4., 4., 3., 4., 5., 5., 4., 5., 7., 6., 4.],\n",
      "        [2., 3., 1., 0., 1., 3., 3., 3., 2., 3., 4., 4., 3., 4., 6., 5., 3.],\n",
      "        [1., 2., 2., 1., 0., 2., 2., 2., 1., 2., 3., 3., 2., 3., 5., 4., 2.],\n",
      "        [3., 4., 4., 3., 2., 0., 2., 2., 1., 2., 3., 3., 2., 3., 5., 4., 4.],\n",
      "        [3., 4., 4., 3., 2., 2., 0., 2., 1., 2., 3., 3., 2., 3., 5., 4., 4.],\n",
      "        [3., 4., 4., 3., 2., 2., 2., 0., 1., 2., 3., 3., 2., 3., 5., 4., 4.],\n",
      "        [2., 3., 3., 2., 1., 1., 1., 1., 0., 1., 2., 2., 1., 2., 4., 3., 3.],\n",
      "        [3., 4., 4., 3., 2., 2., 2., 2., 1., 0., 3., 3., 2., 3., 5., 4., 4.],\n",
      "        [4., 5., 5., 4., 3., 3., 3., 3., 2., 3., 0., 2., 1., 2., 4., 3., 5.],\n",
      "        [4., 5., 5., 4., 3., 3., 3., 3., 2., 3., 2., 0., 1., 2., 4., 3., 5.],\n",
      "        [3., 4., 4., 3., 2., 2., 2., 2., 1., 2., 1., 1., 0., 1., 3., 2., 4.],\n",
      "        [4., 5., 5., 4., 3., 3., 3., 3., 2., 3., 2., 2., 1., 0., 2., 1., 5.],\n",
      "        [6., 7., 7., 6., 5., 5., 5., 5., 4., 5., 4., 4., 3., 2., 0., 1., 7.],\n",
      "        [5., 6., 6., 5., 4., 4., 4., 4., 3., 4., 3., 3., 2., 1., 1., 0., 6.],\n",
      "        [1., 2., 4., 3., 2., 4., 4., 4., 3., 4., 5., 5., 4., 5., 7., 6., 0.]])\n",
      "[[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{(0, 1), (0, 4), (3, 4), (0, 16), (5, 8), (6, 8), (12, 13), (14, 15), (2, 3), (11, 12), (8, 9), (4, 8), (8, 12), (13, 15), (10, 12), (7, 8)}\n",
      "1 DPA 1\n",
      "2 : 17\n",
      "3 Iraqi 17\n",
      "4 authorities 1\n",
      "5 announced 1\n",
      "6 that 1\n",
      "7 they 17\n",
      "8 had 17\n",
      "9 busted 17\n",
      "10 up 17\n",
      "11 3 1\n",
      "12 terrorist 1\n",
      "13 cells 17\n",
      "14 operating 1\n",
      "15 in 17\n",
      "16 Baghdad 1\n",
      "17 . 17\n",
      "===========================FAKE\n",
      "tensor([[0., 2., 2., 1., 1., 1., 2., 2., 2., 2., 1., 1., 2., 1., 2., 1., 1.],\n",
      "        [2., 0., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
      "        [2., 2., 0., 3., 3., 3., 2., 2., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
      "        [1., 3., 3., 0., 2., 2., 3., 3., 3., 3., 2., 2., 3., 2., 3., 2., 2.],\n",
      "        [1., 3., 3., 2., 0., 2., 3., 3., 3., 3., 2., 2., 3., 2., 3., 2., 2.],\n",
      "        [1., 3., 3., 2., 2., 0., 3., 3., 3., 3., 2., 2., 3., 2., 3., 2., 2.],\n",
      "        [2., 2., 2., 3., 3., 3., 0., 2., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
      "        [2., 2., 2., 3., 3., 3., 2., 0., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
      "        [2., 2., 2., 3., 3., 3., 2., 2., 0., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
      "        [2., 2., 2., 3., 3., 3., 2., 2., 2., 0., 3., 3., 2., 3., 2., 3., 1.],\n",
      "        [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 0., 2., 3., 2., 3., 2., 2.],\n",
      "        [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 2., 0., 3., 2., 3., 2., 2.],\n",
      "        [2., 2., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 0., 3., 2., 3., 1.],\n",
      "        [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 2., 2., 3., 0., 3., 2., 2.],\n",
      "        [2., 2., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 2., 3., 0., 3., 1.],\n",
      "        [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 2., 2., 3., 2., 3., 0., 2.],\n",
      "        [1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 1., 2., 1., 2., 0.]])\n",
      "[[0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{(9, 16), (0, 4), (0, 10), (0, 16), (0, 13), (7, 16), (0, 3), (2, 16), (8, 16), (12, 16), (14, 16), (0, 15), (0, 5), (1, 16), (6, 16), (0, 11)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-497508b6b83f>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dists = torch.tensor(dists)\n",
      "<ipython-input-59-497508b6b83f>:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dists = torch.tensor(dists)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([[0., 1., 2., 1., 2., 2., 2., 1., 1., 2., 1., 2., 2., 2., 2., 2., 2., 1.],\n",
       "          [1., 0., 3., 2., 3., 3., 3., 2., 2., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
       "          [2., 3., 0., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
       "          [1., 2., 3., 0., 3., 3., 3., 2., 2., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
       "          [2., 3., 2., 3., 0., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 0., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 2., 0., 3., 3., 2., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
       "          [1., 2., 3., 2., 3., 3., 3., 0., 2., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
       "          [1., 2., 3., 2., 3., 3., 3., 2., 0., 3., 2., 3., 3., 3., 3., 3., 3., 2.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 0., 3., 2., 2., 2., 2., 2., 2., 1.],\n",
       "          [1., 2., 3., 2., 3., 3., 3., 2., 2., 3., 0., 3., 3., 3., 3., 3., 3., 2.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 0., 2., 2., 2., 2., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 0., 2., 2., 2., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 0., 2., 2., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 0., 2., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 0., 2., 1.],\n",
       "          [2., 3., 2., 3., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 0., 1.],\n",
       "          [1., 2., 1., 2., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 1., 1., 1., 0.]]),\n",
       "  tensor([[0., 2., 2., 1., 1., 1., 2., 2., 2., 2., 1., 1., 2., 1., 2., 1., 1.],\n",
       "          [2., 0., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
       "          [2., 2., 0., 3., 3., 3., 2., 2., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
       "          [1., 3., 3., 0., 2., 2., 3., 3., 3., 3., 2., 2., 3., 2., 3., 2., 2.],\n",
       "          [1., 3., 3., 2., 0., 2., 3., 3., 3., 3., 2., 2., 3., 2., 3., 2., 2.],\n",
       "          [1., 3., 3., 2., 2., 0., 3., 3., 3., 3., 2., 2., 3., 2., 3., 2., 2.],\n",
       "          [2., 2., 2., 3., 3., 3., 0., 2., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
       "          [2., 2., 2., 3., 3., 3., 2., 0., 2., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
       "          [2., 2., 2., 3., 3., 3., 2., 2., 0., 2., 3., 3., 2., 3., 2., 3., 1.],\n",
       "          [2., 2., 2., 3., 3., 3., 2., 2., 2., 0., 3., 3., 2., 3., 2., 3., 1.],\n",
       "          [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 0., 2., 3., 2., 3., 2., 2.],\n",
       "          [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 2., 0., 3., 2., 3., 2., 2.],\n",
       "          [2., 2., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 0., 3., 2., 3., 1.],\n",
       "          [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 2., 2., 3., 0., 3., 2., 2.],\n",
       "          [2., 2., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 2., 3., 0., 3., 1.],\n",
       "          [1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 2., 2., 3., 2., 3., 0., 2.],\n",
       "          [1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 2., 2., 1., 2., 1., 2., 0.]])],\n",
       " {})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control task\n",
    "from tree_utils import * \n",
    "from utils import parse_corpus \n",
    "\n",
    "def get_behaviour(behave_dict, token):\n",
    "    if token in behave_dict:\n",
    "        return behave_dict[token]\n",
    "    return np.random.choice([\"beginning\", \"ending\"],p=[1/2,1/2])\n",
    "\n",
    "def fake_gold_distances(corpus, behave_dict):\n",
    "    all_distances = []\n",
    "    ind = 0\n",
    "    for item in corpus:\n",
    "        ind += 1\n",
    "        n = len(item)\n",
    "        modified_heads = np.zeros(n)\n",
    "        words = []\n",
    "        \n",
    "        for word in item:\n",
    "            i = word['id']\n",
    "            words.append(word['form'])\n",
    "            print(i, word['form'], word['head'])\n",
    "            behaviour = get_behaviour(behave_dict, word['form'])\n",
    "            if behaviour == \"beginning\":\n",
    "                modified_heads[i-1] = 1 \n",
    "            elif behaviour == \"ending\":\n",
    "                modified_heads[i-1] = n\n",
    "        print(\"===========================TRUE\")\n",
    "        test = tokentree_to_ete(item.to_tree())\n",
    "        dists = torch.zeros(n,n)\n",
    "        for node1 in test.traverse():\n",
    "            for node2 in test.traverse():\n",
    "                no1 = int(node1.name) - 1\n",
    "                no2 = int(node2.name) - 1\n",
    "                dists[no1,no2] = node1.get_distance(node2)\n",
    "                \n",
    "        #[node2.get_distance(node1) for node2 in test.traverse() for node1 in test.traverse()]\n",
    "        print([node.name for node in test.traverse()])\n",
    "        # Turn it into a tensor, view, append\n",
    "        dists = torch.tensor(dists)\n",
    "        dists = dists.view(n,n)\n",
    "        mst = create_mst(dists)\n",
    "        print(dists)\n",
    "        print(mst)\n",
    "        ed = edges(mst)\n",
    "        print_tikz([],ed, words, \"TRUEnumber\" + str(ind))\n",
    "        print(ed)\n",
    "        \n",
    "        for i, z in enumerate(item):\n",
    "            new_head = int(modified_heads[i])\n",
    "            print(i+1, item[i]['form'], new_head)\n",
    "            z['head'] = new_head\n",
    "            current = z['deps']\n",
    "            z['deps'] = (current[0], new_head)\n",
    "            \n",
    "            if i == 0 :\n",
    "                z['head'] = 0\n",
    "                z['deps'] = (current[0],0)\n",
    "            elif i == (n-1):\n",
    "                z['head'] = 1\n",
    "                z['deps'] = (current[0],1)\n",
    "            \n",
    "        print(\"===========================FAKE\")\n",
    "        tokentree = item.to_tree()\n",
    "        test = tokentree_to_ete(tokentree)\n",
    "        #print(test)\n",
    "        #print(\"Tree\",tokentree_to_nltk(tokentree))\n",
    "        dists = torch.zeros(n,n)\n",
    "        for node1 in test.traverse():\n",
    "            for node2 in test.traverse():\n",
    "                no1 = int(node1.name) - 1\n",
    "                no2 = int(node2.name) - 1\n",
    "                dists[no1,no2] = node1.get_distance(node2)\n",
    "        # Turn it into a tensor, view, append\n",
    "        dists = torch.tensor(dists)\n",
    "        dists = dists.view(n,n)\n",
    "        mst = create_mst(dists)\n",
    "        print(dists)\n",
    "        print(mst)\n",
    "        ed = edges(mst)\n",
    "        print_tikz([],ed, words, \"number\" + str(ind))\n",
    "        print(ed)\n",
    "        all_distances.append(dists)\n",
    "    return all_distances, behave_dict\n",
    "\n",
    "corp = parse_corpus(os.path.join('data', 'en_ewt-ud-'+'train'+'.conllu'))[1:3]\n",
    "fake_gold_distances(corp, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class StructuralProbe(nn.Module):\n",
    "    \"\"\" Computes squared L2 distance after projection by a matrix.\n",
    "    For a batch of sentences, computes all n^2 pairs of distances\n",
    "    for each sentence in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dim, rank, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.probe_rank = rank\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.proj = nn.Parameter(data = torch.zeros(self.model_dim, self.probe_rank))\n",
    "        \n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\" Computes all n^2 pairs of distances after projection\n",
    "        for each sentence in a batch.\n",
    "        Note that due to padding, some distances will be non-zero for pads.\n",
    "        Computes (B(h_i-h_j))^T(B(h_i-h_j)) for all i,j\n",
    "        Args:\n",
    "          batch: a batch of word representations of the shape\n",
    "            (batch_size, max_seq_len, representation_dim)\n",
    "        Returns:\n",
    "          A tensor of distances of shape (batch_size, max_seq_len, max_seq_len)\n",
    "        \"\"\"\n",
    "        transformed = torch.matmul(batch, self.proj)\n",
    "        \n",
    "        batchlen, seqlen, rank = transformed.size()\n",
    "        \n",
    "        transformed = transformed.unsqueeze(2)\n",
    "        transformed = transformed.expand(-1, -1, seqlen, -1)\n",
    "        transposed = transformed.transpose(1,2)\n",
    "        \n",
    "        diffs = transformed - transposed\n",
    "        \n",
    "        squared_diffs = diffs.pow(2)\n",
    "        squared_distances = torch.sum(squared_diffs, -1)\n",
    "\n",
    "        return squared_distances\n",
    "\n",
    "    \n",
    "class L1DistanceLoss(nn.Module):\n",
    "    \"\"\"Custom L1 loss for distance matrices.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, label_batch, length_batch):\n",
    "        \"\"\" Computes L1 loss on distance matrices.\n",
    "        Ignores all entries where label_batch=-1\n",
    "        Normalizes first within sentences (by dividing by the square of the sentence length)\n",
    "        and then across the batch.\n",
    "        Args:\n",
    "          predictions: A pytorch batch of predicted distances\n",
    "          label_batch: A pytorch batch of true distances\n",
    "          length_batch: A pytorch batch of sentence lengths\n",
    "        Returns:\n",
    "          A tuple of:\n",
    "            batch_loss: average loss in the batch\n",
    "            total_sents: number of sentences in the batch\n",
    "        \"\"\"\n",
    "        labels_1s = (label_batch != -1).float()\n",
    "        predictions_masked = predictions * labels_1s\n",
    "        labels_masked = label_batch * labels_1s\n",
    "        total_sents = torch.sum((length_batch != 0)).float()\n",
    "        squared_lengths = length_batch.pow(2).float()\n",
    "\n",
    "        if total_sents > 0:\n",
    "            loss_per_sent = torch.sum(torch.abs(predictions_masked - labels_masked), dim=(1,2))\n",
    "            normalized_loss_per_sent = loss_per_sent / squared_lengths\n",
    "            batch_loss = torch.sum(normalized_loss_per_sent) / total_sents\n",
    "        \n",
    "        else:\n",
    "            batch_loss = torch.tensor(0.0)\n",
    "        \n",
    "        return batch_loss, total_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import math\n",
    "import tree_utils\n",
    "import importlib\n",
    "importlib.reload(tree_utils)\n",
    "\n",
    "# I recommend you to write a method that can evaluate the UUAS & loss score for the dev (& test) corpus.\n",
    "# Feel free to alter the signature of this method.\n",
    "def evaluate_probe(probe, dataloader):\n",
    "    loss_function =  L1DistanceLoss()\n",
    "    probe.eval()\n",
    "    total_loss = 0.0\n",
    "    total_uuas = 0.0\n",
    "    amt = 0.0\n",
    "    for distances, embs, lengths in dataloader:\n",
    "        embs = embs.to(device)\n",
    "        distances = distances.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        amt += len(distances)\n",
    "        outputs = probe(embs)\n",
    "        loss = loss_function(outputs, distances, lengths)[0]\n",
    "        total_loss += loss.item()\n",
    "        for i in range(len(distances)):\n",
    "            l = lengths[i]\n",
    "            preds = outputs[i,0:l, 0:l]\n",
    "            gold = distances[i,0:l, 0:l]\n",
    "            \n",
    "            u = tree_utils.calc_uuas(preds, gold)\n",
    "            if math.isnan(u):\n",
    "                amt -= 1\n",
    "            # This if statement is a hack so nans don't get counted\n",
    "            if u >= 0: total_uuas += u\n",
    "    \n",
    "    return total_loss/amt, total_uuas/amt\n",
    "\n",
    "# Feel free to alter the signature of this method.\n",
    "def train_structural(probe, dataloader, dev_dataloader,test_loader, epochs=100):\n",
    "    lr = 1e-5\n",
    "    batch_size = 128\n",
    "    \n",
    "    optimizer = optim.Adam(probe.parameters(), lr=lr)\n",
    "    #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,patience=1)\n",
    "    loss_function =  L1DistanceLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        probe.train()\n",
    "        for distances, embs, lengths in dataloader:\n",
    "            embs = embs.to(device)\n",
    "            distances = distances.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            outputs = probe(embs)\n",
    "            loss = loss_function(outputs, distances, lengths)[0]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        dev_loss, dev_uuas = evaluate_probe(probe, dev_dataloader)\n",
    "        print(\"Epoch\", epoch, \"Dev loss and uuas\", dev_loss, dev_uuas)\n",
    "        # Using a scheduler is up to you, and might require some hyper param fine-tuning\n",
    "        #scheduler.step(dev_loss)\n",
    "\n",
    "    test_loss, test_uuas = evaluate_probe(probe, test_loader)\n",
    "    print(\"Test loss, uuas\", test_loss, test_uuas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import StructuralDataset, pad_batch\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = data.DataLoader(StructuralDataset(*train_xy), batch_size=batch_size, collate_fn= pad_batch, shuffle=True)\n",
    "dev_loader = data.DataLoader(StructuralDataset(*dev_xy), batch_size=batch_size, collate_fn= pad_batch, shuffle=True)\n",
    "test_loader = data.DataLoader(StructuralDataset(*test_xy), batch_size=batch_size, collate_fn= pad_batch, shuffle=True)\n",
    "\n",
    "emb_dim = 768\n",
    "rank = 64\n",
    "probe = StructuralProbe(emb_dim, rank).to(device)\n",
    "print(probe)\n",
    "train_structural(probe, train_loader, dev_loader, test_loader, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import StructuralDataset, pad_batch\n",
    "\n",
    "batch_size = 32\n",
    "ctrain_loader = data.DataLoader(StructuralDataset(struct_train_control, train_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "cdev_loader = data.DataLoader(StructuralDataset(struct_dev_control, dev_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "ctest_loader = data.DataLoader(StructuralDataset(struct_test_control, test_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "\n",
    "emb_dim = 768\n",
    "rank = 64\n",
    "probe = StructuralProbe(emb_dim, rank).to(device)\n",
    "print(probe)\n",
    "train_structural(probe, ctrain_loader, cdev_loader, ctest_loader, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tree_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_utils import *\n",
    "struct_train_control[1].shape\n",
    "#print(train_xy[1][0].shape)\n",
    "t = edges(create_mst(train_xy[0][1]))\n",
    "print_tikz(t, edges(create_mst(struct_train_control[1])), [\"w\"]*18, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
