{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from conllu import parse_incr, TokenList\n",
    "from torch import Tensor\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "CUTOFF = None\n",
    "from lstm.model import RNNModel\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready\n",
      "Tokenizer ready\n"
     ]
    }
   ],
   "source": [
    "transformer = GPT2Model.from_pretrained('distilgpt2', output_hidden_states=True)\n",
    "print(\"Model ready\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "print(\"Tokenizer ready\")\n",
    "# Note that some models don't return the hidden states by default.\n",
    "# This can be configured by passing `output_hidden_states=True` to the `from_pretrained` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gulordava LSTM model can be found here: \n",
    "# https://drive.google.com/open?id=1w47WsZcZzPyBKDn83cMNd0Hb336e-_Sy\n",
    "#\n",
    "# N.B: I have altered the RNNModel code to only output the hidden states that you are interested in.\n",
    "# If you want to do more experiments with this model you could have a look at the original code here:\n",
    "# https://github.com/facebookresearch/colorlessgreenRNNs/blob/master/src/language_models/model.py\n",
    "#\n",
    "model_location = 'lstm/gulordava.pt'\n",
    "lstm = RNNModel('LSTM', 50001, 650, 650, 2)\n",
    "lstm.load_state_dict(torch.load(model_location))\n",
    "\n",
    "\n",
    "# This LSTM does not use a Tokenizer like the Transformers, but a Vocab dictionary that maps a token to an id.\n",
    "with open('lstm/vocab.txt') as f:\n",
    "    w2i = {w.strip(): i for i, w in enumerate(f)}\n",
    "\n",
    "vocab = defaultdict(lambda: w2i[\"<unk>\"])\n",
    "vocab.update(w2i)\n",
    "i2w = { w2i[k]:k for k in w2i}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data for 12543\n",
      "Doing LSTM: False\n",
      "Data created. Pickling now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/.local/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data for 2002\n",
      "Doing LSTM: False\n",
      "Data created. Pickling now\n",
      "Creating data for 2077\n",
      "Doing LSTM: False\n",
      "Data created. Pickling now\n"
     ]
    }
   ],
   "source": [
    "from utils import create_or_load_pos_data\n",
    "from controltasks import save_or_load_pos_controls \n",
    "from datasets import find_distribution, POSDataset\n",
    "import torch.utils.data as data \n",
    "\n",
    "train_x, train_y, vocab, words_train = create_or_load_pos_data(\"train\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "dev_x, dev_y, vocab, words_dev = create_or_load_pos_data(\"dev\", transformer, tokenizer, vocab, cutoff=CUTOFF)\n",
    "test_x, test_y, vocab, words_test = create_or_load_pos_data(\"test\", transformer, tokenizer, vocab, cutoff=CUTOFF)\n",
    "dist = find_distribution(data.DataLoader(POSDataset(train_x, train_y), batch_size=1))\n",
    "\n",
    "flatten_train = [word for sublist in words_train for word in sublist]\n",
    "flatten_dev   = [word for sublist in words_dev for word in sublist]\n",
    "flatten_test  = [word for sublist in words_test for word in sublist]\n",
    "\n",
    "ypos_train_control, ypos_dev_control, ypos_test_control = save_or_load_pos_controls(\n",
    "    train_x, train_y, [flatten_train, flatten_dev, flatten_test], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching for 12543\n",
      "Doing LSTM: False\n",
      "Data created,pickling\n",
      "Fetching for 2002\n",
      "Doing LSTM: False\n",
      "Data created,pickling\n",
      "Fetching for 2077\n",
      "Doing LSTM: False\n",
      "Data created,pickling\n"
     ]
    }
   ],
   "source": [
    "from tree_utils import create_or_load_structural_data\n",
    "from controltasks import save_or_load_struct_controls\n",
    "\n",
    "train_xy = create_or_load_structural_data(\"train\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "dev_xy = create_or_load_structural_data(\"dev\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "test_xy = create_or_load_structural_data(\"test\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "\n",
    "struct_train_control, struct_dev_control, struct_test_control = save_or_load_struct_controls(cutoff=CUTOFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC CLASSIFIER\n",
    "import torch.nn as nn\n",
    "class POSProbe(nn.Module):\n",
    "    def __init__(self, repr_size, pos_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(repr_size, pos_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "def eval_given_dataloader(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for x,y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs,dim=1)\n",
    "        c = torch.sum(torch.eq(preds, y))\n",
    "        correct += c.item()\n",
    "        total += y.shape[0]\n",
    "    return correct/total\n",
    "    \n",
    "def train(my_model, train_loader, dev_loader, epoch_amount = 10):\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(my_model.parameters())\n",
    "    for i in range(epoch_amount):\n",
    "        my_model.train()\n",
    "        epoch_correct = 0.0\n",
    "        epoch_total = 0.0\n",
    "        for x,y in train_loader:\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = my_model(x)\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            correct = torch.sum(torch.eq(preds, y))\n",
    "            accuracy = correct.item()/y.shape[0]\n",
    "            loss = ce(outputs, y)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            epoch_correct += correct.item()\n",
    "            epoch_total += y.shape[0]\n",
    "        print(\"Epoch\",i,\"accuracy\", epoch_correct/epoch_total, eval_given_dataloader(dev_loader, my_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy 0.8959356746584549 0.8773262287259425\n",
      "Epoch 1 accuracy 0.9208641884791162 0.8822172737394623\n",
      "Epoch 2 accuracy 0.9263240218002298 0.8846429139494194\n",
      "Epoch 3 accuracy 0.9286262433707261 0.8903292508350564\n",
      "Epoch 4 accuracy 0.9299802038272601 0.891561953236838\n",
      "Epoch 5 accuracy 0.9310066720434049 0.8911643073007793\n",
      "Epoch 6 accuracy 0.9317887430652296 0.8911643073007793\n",
      "Epoch 7 accuracy 0.9324632793215534 0.8893351359949101\n",
      "Epoch 8 accuracy 0.9329471857663074 0.8910847781135677\n",
      "Epoch 9 accuracy 0.9333724368844246 0.8889772546524575\n",
      "Test accuracy 0.8864759324195091\n"
     ]
    }
   ],
   "source": [
    "# Normal task\n",
    "ntrain_loader = data.DataLoader(POSDataset(train_x, train_y), batch_size=16)\n",
    "ndev_loader = data.DataLoader(POSDataset(dev_x, dev_y), batch_size=16)\n",
    "ntest_loader = data.DataLoader(POSDataset(test_x, test_y), batch_size=16)\n",
    "\n",
    "model = POSProbe(768, len(dist)).to(device)\n",
    "train(model, ntrain_loader, ndev_loader, 10)\n",
    "print(\"Test accuracy\", eval_given_dataloader(ntest_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204585 204585\n",
      "25148 25148\n",
      "25096 25096\n",
      "Epoch 0 accuracy 0.5241097832196886 0.5309368538253539\n",
      "Epoch 1 accuracy 0.5565852824009581 0.5376173055511373\n",
      "Epoch 2 accuracy 0.559801549478212 0.5392078892953714\n",
      "Epoch 3 accuracy 0.5609355524598577 0.5386909495784953\n",
      "Epoch 4 accuracy 0.5615465454456583 0.5390090663273421\n",
      "Epoch 5 accuracy 0.5619326930126842 0.5390885955145538\n",
      "Epoch 6 accuracy 0.5620548916098443 0.5390885955145538\n",
      "Epoch 7 accuracy 0.5622064178703229 0.5392476538889772\n",
      "Epoch 8 accuracy 0.5623090646919373 0.5390885955145538\n",
      "Epoch 9 accuracy 0.5623921597380062 0.5391283601081597\n",
      "Test accuracy 0.5321166719795983\n"
     ]
    }
   ],
   "source": [
    "# Normal task\n",
    "ctrain_loader = data.DataLoader(POSDataset(train_x, ypos_train_control), batch_size=16)\n",
    "cdev_loader = data.DataLoader(POSDataset(dev_x, ypos_dev_control), batch_size=16)\n",
    "ctest_loader = data.DataLoader(POSDataset(test_x, ypos_test_control), batch_size=16)\n",
    "print(len(ypos_train_control), len(train_x))\n",
    "print(len(ypos_dev_control), len(dev_x))\n",
    "print(len(ypos_test_control), len(test_x))\n",
    "\n",
    "model = POSProbe(768, len(dist)).to(device)\n",
    "train(model, ctrain_loader, cdev_loader, 10)\n",
    "print(\"Test accuracy\", eval_given_dataloader(ctest_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class StructuralProbe(nn.Module):\n",
    "    \"\"\" Computes squared L2 distance after projection by a matrix.\n",
    "    For a batch of sentences, computes all n^2 pairs of distances\n",
    "    for each sentence in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dim, rank, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.probe_rank = rank\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.proj = nn.Parameter(data = torch.zeros(self.model_dim, self.probe_rank))\n",
    "        \n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\" Computes all n^2 pairs of distances after projection\n",
    "        for each sentence in a batch.\n",
    "        Note that due to padding, some distances will be non-zero for pads.\n",
    "        Computes (B(h_i-h_j))^T(B(h_i-h_j)) for all i,j\n",
    "        Args:\n",
    "          batch: a batch of word representations of the shape\n",
    "            (batch_size, max_seq_len, representation_dim)\n",
    "        Returns:\n",
    "          A tensor of distances of shape (batch_size, max_seq_len, max_seq_len)\n",
    "        \"\"\"\n",
    "        transformed = torch.matmul(batch, self.proj)\n",
    "        \n",
    "        batchlen, seqlen, rank = transformed.size()\n",
    "        \n",
    "        transformed = transformed.unsqueeze(2)\n",
    "        transformed = transformed.expand(-1, -1, seqlen, -1)\n",
    "        transposed = transformed.transpose(1,2)\n",
    "        \n",
    "        diffs = transformed - transposed\n",
    "        \n",
    "        squared_diffs = diffs.pow(2)\n",
    "        squared_distances = torch.sum(squared_diffs, -1)\n",
    "\n",
    "        return squared_distances\n",
    "\n",
    "    \n",
    "class L1DistanceLoss(nn.Module):\n",
    "    \"\"\"Custom L1 loss for distance matrices.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, label_batch, length_batch):\n",
    "        \"\"\" Computes L1 loss on distance matrices.\n",
    "        Ignores all entries where label_batch=-1\n",
    "        Normalizes first within sentences (by dividing by the square of the sentence length)\n",
    "        and then across the batch.\n",
    "        Args:\n",
    "          predictions: A pytorch batch of predicted distances\n",
    "          label_batch: A pytorch batch of true distances\n",
    "          length_batch: A pytorch batch of sentence lengths\n",
    "        Returns:\n",
    "          A tuple of:\n",
    "            batch_loss: average loss in the batch\n",
    "            total_sents: number of sentences in the batch\n",
    "        \"\"\"\n",
    "        labels_1s = (label_batch != -1).float()\n",
    "        predictions_masked = predictions * labels_1s\n",
    "        labels_masked = label_batch * labels_1s\n",
    "        total_sents = torch.sum((length_batch != 0)).float()\n",
    "        squared_lengths = length_batch.pow(2).float()\n",
    "\n",
    "        if total_sents > 0:\n",
    "            loss_per_sent = torch.sum(torch.abs(predictions_masked - labels_masked), dim=(1,2))\n",
    "            normalized_loss_per_sent = loss_per_sent / squared_lengths\n",
    "            batch_loss = torch.sum(normalized_loss_per_sent) / total_sents\n",
    "        \n",
    "        else:\n",
    "            batch_loss = torch.tensor(0.0)\n",
    "        \n",
    "        return batch_loss, total_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import math\n",
    "import tree_utils\n",
    "\n",
    "# I recommend you to write a method that can evaluate the UUAS & loss score for the dev (& test) corpus.\n",
    "# Feel free to alter the signature of this method.\n",
    "def evaluate_probe(probe, dataloader):\n",
    "    loss_function =  L1DistanceLoss()\n",
    "    probe.eval()\n",
    "    total_loss = 0.0\n",
    "    total_uuas = 0.0\n",
    "    amt = 0.0\n",
    "    for distances, embs, lengths in dataloader:\n",
    "        embs = embs.to(device)\n",
    "        distances = distances.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        amt += len(distances)\n",
    "        outputs = probe(embs)\n",
    "        loss = loss_function(outputs, distances, lengths)[0]\n",
    "        total_loss += loss.item()\n",
    "        for i in range(len(distances)):\n",
    "            l = lengths[i]\n",
    "            preds = outputs[i,0:l, 0:l]\n",
    "            gold = distances[i,0:l, 0:l]\n",
    "            \n",
    "            u = tree_utils.calc_uuas(preds, gold)\n",
    "            if math.isnan(u):\n",
    "                amt -= 1\n",
    "            # This if statement is a hack so nans don't get counted\n",
    "            if u >= 0: total_uuas += u\n",
    "    \n",
    "    return total_loss/amt, total_uuas/amt\n",
    "\n",
    "# Feel free to alter the signature of this method.\n",
    "def train_structural(probe, dataloader, dev_dataloader,test_loader, epochs=100):\n",
    "    lr = 1e-5\n",
    "    batch_size = 128\n",
    "    \n",
    "    optimizer = optim.Adam(probe.parameters(), lr=lr)\n",
    "    #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,patience=1)\n",
    "    loss_function =  L1DistanceLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        probe.train()\n",
    "        for distances, embs, lengths in dataloader:\n",
    "            embs = embs.to(device)\n",
    "            distances = distances.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            outputs = probe(embs)\n",
    "            loss = loss_function(outputs, distances, lengths)[0]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        dev_loss, dev_uuas = evaluate_probe(probe, dev_dataloader)\n",
    "        print(\"Epoch\", epoch, \"Dev loss and uuas\", dev_loss, dev_uuas)\n",
    "        # Using a scheduler is up to you, and might require some hyper param fine-tuning\n",
    "        #scheduler.step(dev_loss)\n",
    "\n",
    "    test_loss, test_uuas = evaluate_probe(probe, test_loader)\n",
    "    print(\"Test loss, uuas\", test_loss, test_uuas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructuralProbe()\n",
      "Epoch 0 Dev loss and uuas 2.5447451674725103 0.2562101074791884\n",
      "Epoch 1 Dev loss and uuas 1.589373900436578 0.26002308270152175\n",
      "Epoch 2 Dev loss and uuas 1.044382552619236 0.2652228065912948\n",
      "Epoch 3 Dev loss and uuas 0.7241506009949243 0.2752651475166392\n",
      "Epoch 4 Dev loss and uuas 0.5286934759338572 0.2936645898767807\n",
      "Epoch 5 Dev loss and uuas 0.40306736868889426 0.31899045225358164\n",
      "Epoch 6 Dev loss and uuas 0.31722051738815227 0.3485226062280033\n",
      "Epoch 7 Dev loss and uuas 0.25490789308156875 0.3677320221766217\n",
      "Epoch 8 Dev loss and uuas 0.2072790497610371 0.3771351016868157\n",
      "Epoch 9 Dev loss and uuas 0.169515687835204 0.38076268915636563\n",
      "Epoch 10 Dev loss and uuas 0.1390038615897627 0.38418137647964984\n",
      "Epoch 11 Dev loss and uuas 0.11424544231121973 0.3894909850757561\n",
      "Epoch 12 Dev loss and uuas 0.09432310592990317 0.39363481505158915\n",
      "Epoch 13 Dev loss and uuas 0.07853567405955397 0.39782617989280683\n",
      "Epoch 14 Dev loss and uuas 0.06622627010856894 0.40232968404554936\n",
      "Epoch 15 Dev loss and uuas 0.056737477439685824 0.40978731325434004\n",
      "Epoch 16 Dev loss and uuas 0.049533166782587734 0.4164857968356188\n",
      "Epoch 17 Dev loss and uuas 0.04408727105232945 0.4226009535775808\n",
      "Epoch 18 Dev loss and uuas 0.03999184559321679 0.4283780145746915\n",
      "Epoch 19 Dev loss and uuas 0.03690514661034826 0.4352343898149507\n",
      "Epoch 20 Dev loss and uuas 0.03454744430370511 0.4376503108066118\n",
      "Epoch 21 Dev loss and uuas 0.03270264866161547 0.4446317126273918\n",
      "Epoch 22 Dev loss and uuas 0.031211622897633493 0.4503125411348568\n",
      "Epoch 23 Dev loss and uuas 0.029987675753803032 0.4557398210087589\n",
      "Epoch 24 Dev loss and uuas 0.028974219404560533 0.4608249255138113\n",
      "Epoch 25 Dev loss and uuas 0.028136043252127655 0.4666122727236412\n",
      "Epoch 26 Dev loss and uuas 0.027441691807015837 0.4701367029996202\n",
      "Epoch 27 Dev loss and uuas 0.026862068225156622 0.4749924961985721\n",
      "Epoch 28 Dev loss and uuas 0.026382373334481513 0.4781596324077324\n",
      "Epoch 29 Dev loss and uuas 0.025981425361553075 0.48008709256479537\n",
      "Epoch 30 Dev loss and uuas 0.025641124754297997 0.4839487498623841\n",
      "Epoch 31 Dev loss and uuas 0.025359678798042764 0.4870752889898989\n",
      "Epoch 32 Dev loss and uuas 0.025114936861831434 0.4895431469522925\n",
      "Epoch 33 Dev loss and uuas 0.02490244042735496 0.4901906442159356\n",
      "Epoch 34 Dev loss and uuas 0.024716856665165016 0.49059078474060813\n",
      "Epoch 35 Dev loss and uuas 0.02455012667943752 0.4910281084400238\n",
      "Epoch 36 Dev loss and uuas 0.024401877894135806 0.4918416551420149\n",
      "Epoch 37 Dev loss and uuas 0.024268669801931653 0.493037283815525\n",
      "Epoch 38 Dev loss and uuas 0.024148769245789504 0.49482588790012433\n",
      "Epoch 39 Dev loss and uuas 0.02403805791140856 0.496626304245333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eb1bbb8d3e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprobe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStructuralProbe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_structural\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-901938c6f0dd>\u001b[0m in \u001b[0;36mtrain_structural\u001b[0;34m(probe, dataloader, dev_dataloader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f15241a0f984>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbatchlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import StructuralDataset, pad_batch\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = data.DataLoader(StructuralDataset(*train_xy), batch_size=batch_size, collate_fn= pad_batch)\n",
    "dev_loader = data.DataLoader(StructuralDataset(*dev_xy), batch_size=batch_size, collate_fn= pad_batch)\n",
    "test_loader = data.DataLoader(StructuralDataset(*test_xy), batch_size=batch_size, collate_fn= pad_batch)\n",
    "\n",
    "emb_dim = 768\n",
    "rank = 64\n",
    "probe = StructuralProbe(emb_dim, rank).to(device)\n",
    "print(probe)\n",
    "train_structural(probe, train_loader, dev_loader, test_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import StructuralDataset, pad_batch\n",
    "\n",
    "batch_size = 32\n",
    "ctrain_loader = data.DataLoader(StructuralDataset(struct_train_control, train_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "cdev_loader = data.DataLoader(StructuralDataset(struct_dev_control, dev_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "ctest_loader = data.DataLoader(StructuralDataset(struct_test_control, test_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "\n",
    "emb_dim = 768\n",
    "rank = 64\n",
    "probe = StructuralProbe(emb_dim, rank).to(device)\n",
    "print(probe)\n",
    "train_structural(probe, ctrain_loader, cdev_loader, ctest_loader, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
