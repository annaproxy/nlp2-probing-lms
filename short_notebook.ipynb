{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from conllu import parse_incr, TokenList\n",
    "from torch import Tensor\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "CUTOFF = None\n",
    "from lstm.model import RNNModel\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = GPT2Model.from_pretrained('distilgpt2', output_hidden_states=True)\n",
    "print(\"Model ready\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "print(\"Tokenizer ready\")\n",
    "# Note that some models don't return the hidden states by default.\n",
    "# This can be configured by passing `output_hidden_states=True` to the `from_pretrained` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other transformers\n",
    "# BART\n",
    "from transformers import BartModel, BartTokenizer\n",
    "BART = BartModel.from_pretrained('bart-large',output_hidden_states=True)\n",
    "print(\"I have loaded BART!\")\n",
    "BART_tokenizer = BartTokenizer.from_pretrained('bart-large')\n",
    "print(\"I have loaded the BART Tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLNet\n",
    "from transformers import XLNetModel, XLNetTokenizer\n",
    "XLNet = XLNetModel.from_pretrained('xlnet-large-cased', output_hidden_states=True)\n",
    "print(\"I have loaded XLNet!\")\n",
    "XLNet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
    "print(\"I have loaded the XLNet tokenizer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5\n",
    "from transformers import T5Model, T5Tokenizer\n",
    "T5 = T5Model.from_pretrained('t5-small', output_hidden_states=True)\n",
    "print(\"I have loaded T5!\")\n",
    "T5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "print(\"I have loaded the T5 tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gulordava LSTM model can be found here: \n",
    "# https://drive.google.com/open?id=1w47WsZcZzPyBKDn83cMNd0Hb336e-_Sy\n",
    "#\n",
    "# N.B: I have altered the RNNModel code to only output the hidden states that you are interested in.\n",
    "# If you want to do more experiments with this model you could have a look at the original code here:\n",
    "# https://github.com/facebookresearch/colorlessgreenRNNs/blob/master/src/language_models/model.py\n",
    "#\n",
    "model_location = 'lstm/gulordava.pt'\n",
    "lstm = RNNModel('LSTM', 50001, 650, 650, 2)\n",
    "lstm.load_state_dict(torch.load(model_location))\n",
    "\n",
    "\n",
    "# This LSTM does not use a Tokenizer like the Transformers, but a Vocab dictionary that maps a token to an id.\n",
    "with open('lstm/vocab.txt') as f:\n",
    "    w2i = {w.strip(): i for i, w in enumerate(f)}\n",
    "\n",
    "vocabLSTM = defaultdict(lambda: w2i[\"<unk>\"])\n",
    "vocabLSTM.update(w2i)\n",
    "i2w = { w2i[k]:k for k in w2i}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import create_or_load_pos_data\n",
    "from controltasks import save_or_load_pos_controls \n",
    "from datasets import find_distribution, POSDataset\n",
    "import torch.utils.data as data \n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "Change this piece of malevolent code that says CUTOFF = 100 or CUTOFF = 20\n",
    "\"\"\"\n",
    "CUTOFF = None\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def get_transformer_reps(transformer, tokenizer, cutoff=CUTOFF, extra_transformer=None):\n",
    "    \"\"\"\n",
    "    Ugly function that either builds representations for a transformer or retrieves pickled ones\n",
    "    \"\"\"\n",
    "    \n",
    "    train_x, train_y, vocab, words_train = create_or_load_pos_data(\"train\", \n",
    "                                                                   transformer, \n",
    "                                                                   tokenizer, \n",
    "                                                                   cutoff=CUTOFF,\n",
    "                                                                   extra_transformer = extra_transformer)\n",
    "    dev_x, dev_y, vocab, words_dev = create_or_load_pos_data(\"dev\", \n",
    "                                                             transformer, \n",
    "                                                             tokenizer, \n",
    "                                                             vocab, \n",
    "                                                             cutoff=CUTOFF,\n",
    "                                                             extra_transformer = extra_transformer)\n",
    "    test_x, test_y, vocab, words_test = create_or_load_pos_data(\"test\", \n",
    "                                                                transformer, \n",
    "                                                                tokenizer, \n",
    "                                                                vocab, \n",
    "                                                                cutoff=CUTOFF,\n",
    "                                                                extra_transformer = extra_transformer)\n",
    "\n",
    "    # Flatten the wordlists so we have one big list of words for all set types\n",
    "    flatten_train = [word for sublist in words_train for word in sublist]\n",
    "    flatten_dev   = [word for sublist in words_dev for word in sublist]\n",
    "    flatten_test  = [word for sublist in words_test for word in sublist]\n",
    "    \n",
    "    # Generate a distribution over tags, useful for control task\n",
    "    dist = find_distribution(data.DataLoader(POSDataset(train_x, train_y), batch_size=1))\n",
    "    ypos_train_control, ypos_dev_control, ypos_test_control = save_or_load_pos_controls(\n",
    "        train_x, train_y, [flatten_train, flatten_dev, flatten_test], dist)\n",
    "    \n",
    "    #\n",
    "    return train_x, train_y, vocab, words_train, \\\n",
    "           dev_x, dev_y, vocab, words_dev, \\\n",
    "           test_x, test_y, vocab, words_test, \\\n",
    "           flatten_train, flatten_dev, flatten_test, \\\n",
    "           dist, ypos_train_control, ypos_dev_control, ypos_test_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representations for our main transformer, GPT-2\n",
    "train_x, train_y, vocab, words_train, \\\n",
    "           dev_x, dev_y, vocab, words_dev, \\\n",
    "           test_x, test_y, vocab, words_test, \\\n",
    "           flatten_train, flatten_dev, flatten_test, \\\n",
    "           dist, ypos_train_control, ypos_dev_control, ypos_test_control = get_transformer_reps(transformer,\n",
    "                                                                                               tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representations for other transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import create_or_load_pos_data\n",
    "train_x_bart, train_y_bart, vocab, words_train_bart, \\\n",
    "           dev_x_bart, dev_y_bart, vocab_bart, words_dev_bart, \\\n",
    "           test_x_bart, test_y_bart, vocab, words_test_bart, \\\n",
    "           flatten_train_bart, flatten_dev_bart, flatten_test_bart, \\\n",
    "           dist_bart, ypos_train_control_bart, ypos_dev_control_bart, ypos_test_control_bart = \\\n",
    "                    get_transformer_reps(BART, BART_tokenizer, extra_transformer='BART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For XLNet\n",
    "train_x_XLNet, train_y_XLNet, vocab, words_train_XLNet, \\\n",
    "           dev_x_XLNet, dev_y_XLNet, vocab_XLNet, words_dev_XLNet, \\\n",
    "           test_x_XLNet, test_y_XLNet, vocab, words_test_XLNet, \\\n",
    "           flatten_train_XLNet, flatten_dev_XLNet, flatten_test_XLNet, \\\n",
    "           dist_XLNet, ypos_train_control_XLNet, ypos_dev_control_XLNet, ypos_test_control_XLNet = \\\n",
    "                    get_transformer_reps(XLNet, XLNet_tokenizer, extra_transformer='XLNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(3,4)+1\n",
    "a = a.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = XLNet(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(2) + 1\n",
    "b = b.unsqueeze(0)\n",
    "b = b.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_b = XLNet(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For T5\n",
    "train_x_T5, train_y_T5, vocab, words_train_T5, \\\n",
    "           dev_x_T5, dev_y_T5, vocab_T5, words_dev_T5, \\\n",
    "           test_x_T5, test_y_T5, vocab, words_test_T5, \\\n",
    "           flatten_train_T5, flatten_dev_T5, flatten_test_T5, \\\n",
    "           dist_T5, ypos_train_control_T5, ypos_dev_control_T5, ypos_test_control_T5 = \\\n",
    "                    get_transformer_reps(T5, T5_tokenizer, extra_transformer='T5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xL, train_yL, vocab, _ = create_or_load_pos_data(\"train\", lstm, vocabLSTM, cutoff=CUTOFF)\n",
    "dev_xL, dev_yL, vocab, _ = create_or_load_pos_data(\"dev\", lstm, vocabLSTM, vocab, cutoff=CUTOFF)\n",
    "test_xL, test_yL, vocab, _ = create_or_load_pos_data(\"test\", lstm, vocabLSTM, vocab, cutoff=CUTOFF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_utils import create_or_load_structural_data\n",
    "from controltasks import save_or_load_struct_controls\n",
    "\n",
    "train_xy = create_or_load_structural_data(\"train\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "dev_xy = create_or_load_structural_data(\"dev\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "test_xy = create_or_load_structural_data(\"test\", transformer, tokenizer, cutoff=CUTOFF)\n",
    "print(len(train_xy))\n",
    "struct_train_control, struct_dev_control, struct_test_control = save_or_load_struct_controls(cutoff=CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_utils import create_or_load_structural_data\n",
    "from controltasks import save_or_load_struct_controls\n",
    "\n",
    "train_xyLSTM = create_or_load_structural_data(\"train\", lstm, vocabLSTM, cutoff=CUTOFF)\n",
    "dev_xyLSTM = create_or_load_structural_data(\"dev\",     lstm, vocabLSTM, cutoff=CUTOFF)\n",
    "test_xyLSTM = create_or_load_structural_data(\"test\",   lstm, vocabLSTM, cutoff=CUTOFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC CLASSIFIER\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "class POSProbe(nn.Module):\n",
    "    def __init__(self, repr_size, pos_size, hidden_size = 0, dropout=0):\n",
    "        super().__init__()\n",
    "        if hidden_size == 0:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(repr_size, pos_size))\n",
    "        else:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(repr_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(hidden_size, pos_size)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "def eval_given_dataloader(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for x,y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs,dim=1)\n",
    "        c = torch.sum(torch.eq(preds, y))\n",
    "        correct += c.item()\n",
    "        total += y.shape[0]\n",
    "    return correct/total\n",
    "    \n",
    "def train(my_model, train_loader, dev_loader, epoch_amount = 10, warmup_steps = 5, p=False):\n",
    "    \"\"\"\n",
    "    Given a model, train_loader and dev_loader\n",
    "    \n",
    "    Returns state_dict for the best epoch\n",
    "    \"\"\"\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(my_model.parameters(), lr=1e-3)\n",
    "    patience = 3\n",
    "    best_model = None\n",
    "    prev_dev_acc = 0.0\n",
    "    best_dev_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    for i in range(epoch_amount):\n",
    "        my_model.train()\n",
    "        epoch_correct = 0.0\n",
    "        epoch_total = 0.0\n",
    "        for x,y in train_loader:\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = my_model(x)\n",
    "            preds = torch.argmax(outputs,dim=1)\n",
    "            correct = torch.sum(torch.eq(preds, y))\n",
    "            accuracy = correct.item()/y.shape[0]\n",
    "            loss = ce(outputs, y)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            epoch_correct += correct.item()\n",
    "            epoch_total += y.shape[0]\n",
    "            \n",
    "        dev_acc = eval_given_dataloader(dev_loader, my_model)\n",
    "        \n",
    "        if p:\n",
    "            print(\"Epoch\",i,\"accuracy\", epoch_correct/epoch_total, dev_acc)        \n",
    "        if dev_acc < prev_dev_acc and i > warmup_steps:\n",
    "            patience -= 1\n",
    "        else:\n",
    "            patience = 2\n",
    "        if dev_acc > best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            best_model = copy.deepcopy(my_model.state_dict())\n",
    "            best_epoch = i\n",
    "        prev_dev_acc = dev_acc\n",
    "        if patience == 0:\n",
    "            #print(\"Early stopping\")\n",
    "            break\n",
    "    return best_model, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP vs LINEAR\n",
    "# Dropout 0.0 0.2 0.4 0.6 0.8 \n",
    "# POS CONTROLPOS\n",
    "# RNN vs Transformer\n",
    "# result_dict[task][model][mlp][dropout][seed] -> bestmodel: statedict, val_acc: float, test_acc:float\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "if os.path.exists('true_results.pickle'):\n",
    "    raise ValueError(\"Do not run this ... \")\n",
    "\n",
    "def eval_model(task, model_type, hidden_size, dropout, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        x_train = train_xL\n",
    "        x_dev = dev_xL \n",
    "        x_test = test_xL\n",
    "    elif model_type == 'transformer':\n",
    "        x_train = train_x\n",
    "        x_dev = dev_x\n",
    "        x_test = test_x\n",
    "    elif model_type == 'BART':\n",
    "        x_train = train_x_bart\n",
    "        x_dev   = dev_x_bart\n",
    "        x_test  = test_x_bart\n",
    "    elif model_type == 'XLNet':\n",
    "        x_train = train_x_XLNet\n",
    "        x_dev   = dev_x_XLNet\n",
    "        x_test  = test_x_XLNet\n",
    "    elif model_type == 'T5':\n",
    "        pass\n",
    "    \n",
    "    if task == 'pos':\n",
    "        y_train = train_y\n",
    "        y_dev = dev_y\n",
    "        y_test = test_y\n",
    "    else:\n",
    "        y_train = ypos_train_control\n",
    "        y_dev = ypos_dev_control\n",
    "        y_test = ypos_test_control\n",
    "        \n",
    "    train_loader = data.DataLoader(POSDataset(x_train, y_train), batch_size=16, shuffle=True)\n",
    "    dev_loader = data.DataLoader(POSDataset(x_dev, y_dev), batch_size=16)\n",
    "    test_loader = data.DataLoader(POSDataset(x_test, y_test), batch_size=16)\n",
    "\n",
    "    #model = POSProbe(768 if model_type == 'transformer' else 650, len(dist), hidden_size, dropout).to(device)\n",
    "    # Change model based on model type\n",
    "    if model_type == 'transformer': dim = 768\n",
    "    if model_type == 'lstm': dim = 650\n",
    "    else: dim = 1024\n",
    "    model = POSProbe(dim, len(dist), hidden_size, dropout).to(device)\n",
    "    \n",
    "    #\n",
    "    best_state_dict, epochs = train(model, train_loader, dev_loader, 20, 4)\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    dev_acc =  eval_given_dataloader(dev_loader, model)\n",
    "    test_acc = eval_given_dataloader(test_loader, model)\n",
    "    return model, dev_acc, test_acc, epochs\n",
    "print(device)\n",
    "\n",
    "# For XLNet and BART\n",
    "run_other_transformers = True\n",
    "\n",
    "# Decide what models to run\n",
    "if run_other_transformers:\n",
    "    model_list = ['BART', 'XLNet']\n",
    "else:\n",
    "    model_list = ['lstm', 'transformer']\n",
    "\n",
    "#\n",
    "result_dict_mlp = {}   \n",
    "for task in ['pos', 'controlpos']:\n",
    "    result_dict_mlp[task] = {}\n",
    "    for model_type in model_list:\n",
    "        print(\"Starting\", model_type)\n",
    "        result_dict_mlp[task][model_type]= {}\n",
    "        for hidden_size in [0, 256]:\n",
    "            result_dict_mlp[task][model_type][hidden_size] = {}\n",
    "            for dropout in [0,0.2,0.4,0.6,0.8]:\n",
    "                result_dict_mlp[task][model_type][hidden_size][dropout] = {}\n",
    "                for seed in [10,20,30]:\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed] = {}\n",
    "                    state_dict, dev_acc, test_acc, epochs = eval_model(task, model_type, hidden_size, dropout, seed)\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['state_dict'] = state_dict\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['dev_acc'] = dev_acc\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['test_acc'] = test_acc\n",
    "                    result_dict_mlp[task][model_type][hidden_size][dropout][seed]['epochs'] = epochs\n",
    "                    print(task,model_type,hidden_size,dropout,seed, epochs, test_acc)\n",
    "                #print(result_dict)\n",
    "                \n",
    "if run_other_transformers:\n",
    "    with open(\"transformer_results.pickle\", \"wb\") as f:\n",
    "        pickle.dump(result_dict_mlp, f)\n",
    "else: \n",
    "    with open(\"results_and_models.pickle\", \"wb\") as f:\n",
    "        pickle.dump(result_dict_mlp, f)\n",
    "print(\"All results are safe. You can sleep peacefully. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "if run_other_transformers:\n",
    "    with open(\"true_results.pickle\", \"rb\") as f:\n",
    "        dd = pickle.load(f)\n",
    "    \n",
    "else:\n",
    "    with open(\"true_results.pickle\", \"rb\") as f:\n",
    "        dd = pickle.load(f)\n",
    "\n",
    "def mean_test_acc(the_dict):\n",
    "    three_accs = [the_dict[z]['test_acc'] for z in the_dict]\n",
    "    return np.mean(three_accs), np.std(three_accs)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "\n",
    "for model in ['lstm', 'transformer']:\n",
    "    for hidden_size in [0, 256]:\n",
    "        x_axis = [0,0.2,0.4,0.6,0.8]\n",
    "        y_axis = []\n",
    "        y_axis_control = []\n",
    "        y_axis_select = []\n",
    "        for d in x_axis :\n",
    "            # Mean for POS task\n",
    "            mean = mean_test_acc(dd['pos'][model][hidden_size][d])\n",
    "            #if hidden_size > 0: mean = mean_test_acc(mlp_results['pos'][model][hidden_size][d])\n",
    "            \n",
    "            # Mean for Control task\n",
    "            mean_control = mean_test_acc(dd['controlpos'][model][hidden_size][d])\n",
    "            #if hidden_size > 0: mean_control = mean_test_acc(mlp_results2['controlpos'][model][hidden_size][d])\n",
    "            \n",
    "            # Append\n",
    "            y_axis.append(mean[0])\n",
    "            y_axis_select.append(mean[0] - mean_control[0])\n",
    "\n",
    "        ax1.plot(x_axis, y_axis, '--o', label=model+str(hidden_size), )\n",
    "        ax2.plot(x_axis, y_axis_select, '--o')\n",
    "        ax1.legend()\n",
    "    \n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax2.set_title(\"Selectivity\")\n",
    "ax1.set_xlabel(\"Dropout\")\n",
    "ax2.set_xlabel(\"Dropout\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raise ValueError(\"This was a temporary fix. \")\n",
    "result_dict1 = {}\n",
    "for task in ['pos', 'controlpos']:\n",
    "    result_dict1[task] = {}\n",
    "    for model_type in ['lstm', 'transformer']:\n",
    "        result_dict1[task][model_type]= {}\n",
    "        for hidden_size in [0, 256]:\n",
    "            result_dict1[task][model_type][hidden_size] = {}\n",
    "            for dropout in [0,0.2,0.4,0.6,0.8]:\n",
    "                result_dict1[task][model_type][hidden_size][dropout] = {}\n",
    "                for seed in [10,20,30]:\n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed] = {}\n",
    "                    \n",
    "                    \n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed]['dev_acc'] = \\\n",
    "                            result_dict[task][model_type][hidden_size][dropout][seed]['dev_acc']\n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed]['test_acc'] = \\\n",
    "                            result_dict[task][model_type][hidden_size][dropout][seed]['test_acc']                    \n",
    "                    result_dict1[task][model_type][hidden_size][dropout][seed]['epochs'] = \\\n",
    "                            result_dict[task][model_type][hidden_size][dropout][seed]['epochs']                    \n",
    "                    \n",
    "                    if hidden_size > 0:\n",
    "                        if task == 'pos':\n",
    "                            result_dict1[task][model_type][hidden_size][dropout][seed]['dev_acc'] = \\\n",
    "                                    mlp_results[task][model_type][hidden_size][dropout][seed]['dev_acc']\n",
    "                            result_dict1[task][model_type][hidden_size][dropout][seed]['test_acc'] = \\\n",
    "                                    mlp_results[task][model_type][hidden_size][dropout][seed]['test_acc']                    \n",
    "                            result_dict1[task][model_type][hidden_size][dropout][seed]['epochs'] = \\\n",
    "                                    mlp_results[task][model_type][hidden_size][dropout][seed]['epochs']  \n",
    "                        else:\n",
    "                            result_dict1[task][model_type][hidden_size][dropout][seed]['dev_acc'] = \\\n",
    "                                    mlp_results2[task][model_type][hidden_size][dropout][seed]['dev_acc']\n",
    "                            result_dict1[task][model_type][hidden_size][dropout][seed]['test_acc'] = \\\n",
    "                                    mlp_results2[task][model_type][hidden_size][dropout][seed]['test_acc']                    \n",
    "                            result_dict1[task][model_type][hidden_size][dropout][seed]['epochs'] = \\\n",
    "                                    mlp_results2[task][model_type][hidden_size][dropout][seed]['epochs']  \n",
    "\n",
    "with open(\"true_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(result_dict1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmtrain_loader = data.DataLoader(POSDataset(train_xL, train_yL), batch_size=16, shuffle=True)\n",
    "lstmdev_loader = data.DataLoader(POSDataset(dev_xL, dev_yL), batch_size=16)\n",
    "lstmtest_loader = data.DataLoader(POSDataset(test_xL, test_yL), batch_size=16)\n",
    "\n",
    "model = POSProbe(650, len(dist)).to(device)\n",
    "model.load_state_dict(train(model, lstmtrain_loader, lstmdev_loader, 30,10, p=True))\n",
    "print(\"Dev accuracy\", eval_given_dataloader(lstmdev_loader, model))\n",
    "print(\"Test accuracy\", eval_given_dataloader(lstmtest_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal task\n",
    "ctrain_loader = data.DataLoader(POSDataset(train_x, ypos_train_control), batch_size=16)\n",
    "cdev_loader = data.DataLoader(POSDataset(dev_x, ypos_dev_control), batch_size=16)\n",
    "ctest_loader = data.DataLoader(POSDataset(test_x, ypos_test_control), batch_size=16)\n",
    "print(train_x.shape, ypos_train_control.shape)\n",
    "model = POSProbe(768, len(dist), hidden_size=256).to(device)\n",
    "model.load_state_dict(train(model, ctrain_loader, cdev_loader, 20, p=True))\n",
    "print(\"Test accuracy\", eval_given_dataloader(ctest_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control task\n",
    "from tree_utils import * \n",
    "from utils import parse_corpus \n",
    "\n",
    "def get_behaviour(behave_dict, token):\n",
    "    if token in behave_dict:\n",
    "        return behave_dict[token]\n",
    "    return np.random.choice([\"beginning\", \"ending\"],p=[1/2,1/2])\n",
    "\n",
    "def fake_gold_distances(corpus, behave_dict):\n",
    "    all_distances = []\n",
    "    ind = 0\n",
    "    for item in corpus:\n",
    "        \n",
    "        n = len(item)\n",
    "        modified_heads = np.zeros(n)\n",
    "        words = []\n",
    "        # Calculate new heads\n",
    "        for word in item:\n",
    "            i = word['id']\n",
    "            words.append(word['form'])\n",
    "            #print(i, word['form'], word['head'])\n",
    "            behaviour = get_behaviour(behave_dict, word['form'])\n",
    "            if behaviour == \"beginning\":\n",
    "                modified_heads[i-1] = 1 \n",
    "            elif behaviour == \"ending\":\n",
    "                modified_heads[i-1] = n\n",
    "                \n",
    "        # Actually set new heads\n",
    "        for i, z in enumerate(item):\n",
    "            new_head = int(modified_heads[i])\n",
    "            z['head'] = new_head\n",
    "            \n",
    "            if i == 0 :\n",
    "                z['head'] = 0\n",
    "            elif i == (n-1):\n",
    "                z['head'] = 1\n",
    "            \n",
    "        tokentree = item.to_tree()\n",
    "        test = tokentree_to_ete(tokentree)\n",
    "        dists = torch.zeros(n,n)\n",
    "        for node1 in test.traverse():\n",
    "            for node2 in test.traverse():\n",
    "                no1 = int(node1.name) - 1\n",
    "                no2 = int(node2.name) - 1\n",
    "                dists[no1,no2] = node1.get_distance(node2)\n",
    "        # Turn it into a tensor, view, append\n",
    "        #dists = dists.view(n,n)\n",
    "        mst = create_mst(dists)\n",
    "        ed = edges(mst)\n",
    "        #print_tikz([],ed, words, \"number\" + str(ind))\n",
    "        all_distances.append(dists)\n",
    "    return all_distances, behave_dict\n",
    "\n",
    "corp = parse_corpus(os.path.join('data','sample', 'en_ewt-ud-'+'train'+'.conllu'))\n",
    "fake = fake_gold_distances(corp, {})\n",
    "\n",
    "#print([z.shape for z in fake[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class StructuralProbe(nn.Module):\n",
    "    \"\"\" Computes squared L2 distance after projection by a matrix.\n",
    "    For a batch of sentences, computes all n^2 pairs of distances\n",
    "    for each sentence in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dim, rank, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.probe_rank = rank\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.proj = nn.Parameter(data = torch.zeros(self.model_dim, self.probe_rank))\n",
    "        \n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        #self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\" Computes all n^2 pairs of distances after projection\n",
    "        for each sentence in a batch.\n",
    "        Note that due to padding, some distances will be non-zero for pads.\n",
    "        Computes (B(h_i-h_j))^T(B(h_i-h_j)) for all i,j\n",
    "        Args:\n",
    "          batch: a batch of word representations of the shape\n",
    "            (batch_size, max_seq_len, representation_dim)\n",
    "        Returns:\n",
    "          A tensor of distances of shape (batch_size, max_seq_len, max_seq_len)\n",
    "        \"\"\"\n",
    "        batch = self.dropout(batch)\n",
    "        transformed = torch.matmul(batch, self.proj)\n",
    "        \n",
    "        batchlen, seqlen, rank = transformed.size()\n",
    "        \n",
    "        transformed = transformed.unsqueeze(2)\n",
    "        transformed = transformed.expand(-1, -1, seqlen, -1)\n",
    "        transposed = transformed.transpose(1,2)\n",
    "        \n",
    "        diffs = transformed - transposed\n",
    "        \n",
    "        squared_diffs = diffs.pow(2)\n",
    "        squared_distances = torch.sum(squared_diffs, -1)\n",
    "\n",
    "        return squared_distances\n",
    "\n",
    "    \n",
    "class L1DistanceLoss(nn.Module):\n",
    "    \"\"\"Custom L1 loss for distance matrices.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, label_batch, length_batch):\n",
    "        \"\"\" Computes L1 loss on distance matrices.\n",
    "        Ignores all entries where label_batch=-1\n",
    "        Normalizes first within sentences (by dividing by the square of the sentence length)\n",
    "        and then across the batch.\n",
    "        Args:\n",
    "          predictions: A pytorch batch of predicted distances\n",
    "          label_batch: A pytorch batch of true distances\n",
    "          length_batch: A pytorch batch of sentence lengths\n",
    "        Returns:\n",
    "          A tuple of:\n",
    "            batch_loss: average loss in the batch\n",
    "            total_sents: number of sentences in the batch\n",
    "        \"\"\"\n",
    "        labels_1s = (label_batch != -1).float()\n",
    "        predictions_masked = predictions * labels_1s\n",
    "        labels_masked = label_batch * labels_1s\n",
    "        total_sents = torch.sum((length_batch != 0)).float()\n",
    "        squared_lengths = length_batch.pow(2).float()\n",
    "\n",
    "        if total_sents > 0:\n",
    "            loss_per_sent = torch.sum(torch.abs(predictions_masked - labels_masked), dim=(1,2))\n",
    "            normalized_loss_per_sent = loss_per_sent / squared_lengths\n",
    "            batch_loss = torch.sum(normalized_loss_per_sent) / total_sents\n",
    "        \n",
    "        else:\n",
    "            batch_loss = torch.tensor(0.0)\n",
    "        \n",
    "        return batch_loss, total_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import math\n",
    "import tree_utils\n",
    "import importlib\n",
    "importlib.reload(tree_utils)\n",
    "import copy\n",
    "\n",
    "\n",
    "# I recommend you to write a method that can evaluate the UUAS & loss score for the dev (& test) corpus.\n",
    "# Feel free to alter the signature of this method.\n",
    "def evaluate_probe(probe, dataloader):\n",
    "    loss_function =  L1DistanceLoss()\n",
    "    probe.eval()\n",
    "    total_loss = 0.0\n",
    "    total_uuas = 0.0\n",
    "    amt = 0.0\n",
    "    for last ,(distances, embs, lengths) in enumerate(dataloader):\n",
    "        embs = embs.to(device)\n",
    "        distances = distances.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        amt += len(distances)\n",
    "        outputs = probe(embs)\n",
    "        loss = loss_function(outputs, distances, lengths)[0]\n",
    "        total_loss += loss.item()\n",
    "        for i in range(len(distances)):\n",
    "            l = lengths[i]\n",
    "            preds = outputs[i,0:l, 0:l]\n",
    "            gold = distances[i,0:l, 0:l]\n",
    "            \n",
    "            u = tree_utils.calc_uuas(preds, gold)\n",
    "            if math.isnan(u):\n",
    "                amt -= 1\n",
    "            # This if statement is a hack so nans don't get counted\n",
    "            if u >= 0: total_uuas += u\n",
    "            \n",
    "    \n",
    "    return total_loss/amt, total_uuas/amt\n",
    "\n",
    "# Feel free to alter the signature of this method.\n",
    "def train_structural(probe, dataloader, dev_dataloader, epochs=100, warmup_steps = 10,p =False):\n",
    "    lr = 1e-3\n",
    "    \n",
    "    optimizer = optim.Adam(probe.parameters(), lr=lr)\n",
    "    #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,patience=1)\n",
    "    loss_function =  L1DistanceLoss()\n",
    "    prev_dev_uuas = 0.0\n",
    "    patience = 3\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    best_dev_uuas = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        probe.train()\n",
    "        for distances, embs, lengths in dataloader:\n",
    "            embs = embs.to(device)\n",
    "            distances = distances.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            outputs = probe(embs)\n",
    "            loss = loss_function(outputs, distances, lengths)[0]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        dev_loss, dev_uuas = evaluate_probe(probe, dev_dataloader)\n",
    "        \n",
    "        if p:\n",
    "            print(\"Epoch\", epoch, \"Dev loss and uuas\", dev_loss, dev_uuas)\n",
    "        if dev_uuas < prev_dev_uuas and epoch > warmup_steps:\n",
    "            patience -= 1\n",
    "        else:\n",
    "            patience = 3\n",
    "        if dev_uuas > best_dev_uuas :\n",
    "            best_dev_uuas  = dev_uuas \n",
    "            best_model = copy.deepcopy(probe.state_dict())\n",
    "            best_epoch = epoch\n",
    "        prev_dev_uuas  = dev_uuas \n",
    "        if patience == 0:\n",
    "            #print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # Using a scheduler is up to you, and might require some hyper param fine-tuning\n",
    "        #scheduler.step(dev_loss)\n",
    "    return best_model, best_epoch\n",
    "    #test_loss, test_uuas = evaluate_probe(probe, test_loader)\n",
    "    #print(\"Test loss, uuas\", test_loss, test_uuas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP vs LINEAR\n",
    "# Dropout 0.0 0.2 0.4 0.6 0.8 \n",
    "# POS CONTROLPOS\n",
    "# RNN vs Transformer\n",
    "# result_dict[task][model][mlp][dropout][seed] -> bestmodel: statedict, val_acc: float, test_acc:float\n",
    "import pickle\n",
    "import os \n",
    "import time \n",
    "\n",
    "if os.path.exists('struct_results_and_models.pickle'):\n",
    "    raise ValueError(\"Do not run this ... \")\n",
    "\n",
    "def eval_model(task, model_type, rank, dropout, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        x_train = train_xyLSTM[1]\n",
    "        x_dev = dev_xyLSTM[1]\n",
    "        x_test = test_xyLSTM[1]\n",
    "    else:\n",
    "        x_train = train_xy[1]\n",
    "        x_dev = dev_xy[1]\n",
    "        x_test = test_xy[1]\n",
    "    \n",
    "    if task == 'dep':\n",
    "        y_train = train_xy[0]\n",
    "        y_dev = dev_xy[0]\n",
    "        y_test = test_xy[0]\n",
    "    else:\n",
    "        y_train = struct_train_control\n",
    "        y_dev = struct_dev_control\n",
    "        y_test = struct_test_control\n",
    "        \n",
    "    train_loader = data.DataLoader(StructuralDataset(y_train, x_train), batch_size=32,collate_fn= pad_batch, shuffle=True)\n",
    "    dev_loader = data.DataLoader(StructuralDataset(y_dev, x_dev), collate_fn= pad_batch,batch_size=32)\n",
    "    test_loader = data.DataLoader(StructuralDataset(y_test, x_test),collate_fn= pad_batch, batch_size=32)\n",
    "\n",
    "    model = StructuralProbe(768 if model_type == 'transformer' else 650,\n",
    "                            rank =rank, dropout=dropout).to(device)\n",
    "    best_state_dict, epochs = train_structural(model, train_loader, dev_loader, epochs=30, warmup_steps=6)\n",
    "    model.load_state_dict(best_state_dict)\n",
    "    dev_acc =  evaluate_probe(model, dev_loader)\n",
    "    test_acc = evaluate_probe(model, test_loader)\n",
    "    return model, dev_acc, test_acc, epochs\n",
    "\n",
    "\n",
    "print(device)\n",
    "result_dict = {}  \n",
    "\n",
    "for task in ['dep', 'controldep']:\n",
    "    result_dict[task] = {}\n",
    "    for model_type in ['lstm', 'transformer']:\n",
    "        print(\"Starting\", model_type)\n",
    "        result_dict[task][model_type]= {}\n",
    "        for rank in [16,64,128]:\n",
    "            result_dict[task][model_type][rank] = {}\n",
    "            for dropout in [0,0.2,0.4,0.6,0.8]:\n",
    "                result_dict[task][model_type][rank][dropout] = {}\n",
    "                for seed in [10,20,30]:\n",
    "                    starttime = time.time()\n",
    "                    result_dict[task][model_type][rank][dropout][seed] = {}\n",
    "                    state_dict, dev_acc, test_acc, epochs = eval_model(task, model_type, rank, dropout, seed)\n",
    "                    result_dict[task][model_type][rank][dropout][seed]['state_dict'] = state_dict\n",
    "                    result_dict[task][model_type][rank][dropout][seed]['dev_acc'] = dev_acc[1]\n",
    "                    result_dict[task][model_type][rank][dropout][seed]['test_acc'] = test_acc[1]\n",
    "                    result_dict[task][model_type][rank][dropout][seed]['epochs'] = epochs\n",
    "                    print(task,model_type,rank,dropout,seed, epochs, test_acc)\n",
    "                    stoptime = time.time() -starttime\n",
    "                    print('Time elapsed %s' % stoptime)\n",
    "                #print(result_dict)       \n",
    "with open(\"structresults_and_models.pickle\", \"wb\") as f:\n",
    "    pickle.dump(result_dict, f)\n",
    "print(\"All results are safe. You can sleep peacefully. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import StructuralDataset, pad_batch\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = data.DataLoader(StructuralDataset(*train_xy), batch_size=batch_size, collate_fn= pad_batch, shuffle=True)\n",
    "dev_loader = data.DataLoader(StructuralDataset(*dev_xy), batch_size=batch_size, collate_fn= pad_batch, shuffle=True)\n",
    "test_loader = data.DataLoader(StructuralDataset(*test_xy), batch_size=batch_size, collate_fn= pad_batch, shuffle=True)\n",
    "\n",
    "emb_dim = 768\n",
    "rank = 64\n",
    "probe = StructuralProbe(emb_dim, rank, dropout=0.2 ).to(device)\n",
    "\n",
    "best_state_dict, epochs = train_structural(probe, train_loader, dev_loader,  epochs=20, warmup_steps=6, p=True)\n",
    "probe.load_state_dict(best_state_dict)\n",
    "dev_acc =  evaluate_probe(probe, dev_loader)\n",
    "test_acc = evaluate_probe(probe, test_loader)\n",
    "print(dev_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import StructuralDataset, pad_batch\n",
    "\n",
    "batch_size = 32\n",
    "ctrain_loader = data.DataLoader(StructuralDataset(struct_train_control, train_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "cdev_loader = data.DataLoader(StructuralDataset(struct_dev_control, dev_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "ctest_loader = data.DataLoader(StructuralDataset(struct_test_control, test_xy[1]), batch_size=batch_size, collate_fn= pad_batch)\n",
    "\n",
    "emb_dim = 768\n",
    "rank = 64\n",
    "probe = StructuralProbe(emb_dim, rank).to(device)\n",
    "print(probe)\n",
    "train_structural(probe, ctrain_loader, cdev_loader, ctest_loader, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open(\"structresults_and_models.pickle\", \"rb\") as f:\n",
    "    dd = pickle.load(f)\n",
    "print(dd)\n",
    "def mean_test_acc(the_dict):\n",
    "    three_accs = [the_dict[z]['test_acc'] for z in the_dict]\n",
    "    return np.mean(three_accs), np.std(three_accs)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "\n",
    "for model in ['lstm', 'transformer']:\n",
    "    for hidden_size in [16,64,128]:\n",
    "        x_axis = [0,0.2,0.4,0.6,0.8]\n",
    "        y_axis = []\n",
    "        y_axis_control = []\n",
    "        y_axis_select = []\n",
    "        for d in x_axis :\n",
    "            # Mean for POS task\n",
    "            mean = mean_test_acc(dd['dep'][model][hidden_size][d])\n",
    "            #if hidden_size > 0: mean = mean_test_acc(mlp_results['pos'][model][hidden_size][d])\n",
    "            \n",
    "            # Mean for Control task\n",
    "            mean_control = mean_test_acc(dd['controldep'][model][hidden_size][d])\n",
    "            #if hidden_size > 0: mean_control = mean_test_acc(mlp_results2['controlpos'][model][hidden_size][d])\n",
    "            \n",
    "            # Append\n",
    "            y_axis.append(mean[0])\n",
    "            y_axis_select.append(mean[0] - mean_control[0])\n",
    "\n",
    "        ax1.plot(x_axis, y_axis, '--o', label=model+str(hidden_size), )\n",
    "        ax2.plot(x_axis, y_axis_select, '--o')\n",
    "        ax1.legend()\n",
    "    \n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax2.set_title(\"Selectivity\")\n",
    "ax1.set_xlabel(\"Dropout\")\n",
    "ax2.set_xlabel(\"Dropout\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
